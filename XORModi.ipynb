{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XMUJNnqzXAAm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(weights=\"imagenet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h06zEbhGUhgE",
        "outputId": "880f94f1-016f-44e9-e6cf-ce02b767eae9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"Dog.jpg\"\n",
        "img = image.load_img(img_path,target_size=(224,224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis = 0)\n",
        "x = preprocess_input(x)"
      ],
      "metadata": {
        "id": "OvE957nQUwtk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(x)\n",
        "print(\"Predicted :\", decode_predictions(preds, top=3)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq2_32AlW9T6",
        "outputId": "6c07d21b-7549-4d3c-d46b-ede1c70d7d5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "Predicted : [('n02109525', 'Saint_Bernard', 0.9096365), ('n02108089', 'boxer', 0.038048156), ('n02109047', 'Great_Dane', 0.025297264)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def train(X, Y, epochs, learning_rate):\n",
        "    w1 = np.random.rand(2, 2)\n",
        "    b1 = np.random.rand(1, 2)\n",
        "    w2 = np.random.rand(2, 1)\n",
        "    b2 = np.random.rand(1, 1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        z1 = np.dot(X, w1) + b1\n",
        "        a1 = sigmoid(z1)\n",
        "        z2 = np.dot(a1, w2) + b2\n",
        "        a2 = sigmoid(z2)\n",
        "\n",
        "        error = Y - a2\n",
        "\n",
        "        d_a2 = error * sigmoid_derivative(a2)\n",
        "        d_w2 = np.dot(a1.T, d_a2)\n",
        "        d_b2 = np.sum(d_a2, axis=0)\n",
        "\n",
        "        d_a1 = np.dot(d_a2, w2.T) * sigmoid_derivative(a1)\n",
        "        d_w1 = np.dot(X.T, d_a1)\n",
        "        d_b1 = np.sum(d_a1, axis=0)\n",
        "\n",
        "        w2 += learning_rate * d_w2\n",
        "        b2 += learning_rate * d_b2\n",
        "        w1 += learning_rate * d_w1\n",
        "        b1 += learning_rate * d_b1\n",
        "\n",
        "    return w1, b1, w2, b2\n",
        "\n",
        "def predict(X, w1, b1, w2, b2):\n",
        "    z1 = np.dot(X, w1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, w2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "    return np.round(a2)\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "epochs = 10000\n",
        "learning_rate = 0.1\n",
        "w1, b1, w2, b2 = train(X, Y, epochs, learning_rate)\n",
        "\n",
        "for x, y in zip(X, Y):\n",
        "    print(f\"Input: {x}, Predicted: {predict(x, w1, b1, w2, b2)[0][0]}, Actual: {y[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY3b9XSIYYy0",
        "outputId": "09208741-6736-4a04-8cd1-119bbc6520f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [0 0], Predicted: 0.0, Actual: 0\n",
            "Input: [0 1], Predicted: 0.0, Actual: 1\n",
            "Input: [1 0], Predicted: 1.0, Actual: 1\n",
            "Input: [1 1], Predicted: 1.0, Actual: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. ReLU Activation Function and its Derivative\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "# Sigmoid activation for output layer\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# 4. Mean Squared Error Loss Function\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "# 6. Train function with added learning rate decay and early stopping\n",
        "def train(X, Y, epochs, initial_learning_rate, decay_rate, patience):\n",
        "    # 2. Architecture: Add more neurons in the hidden layer\n",
        "    w1 = np.random.randn(2, 4) * np.sqrt(1 / 2)  # Xavier initialization\n",
        "    b1 = np.zeros((1, 4))  # Xavier initialization\n",
        "\n",
        "    w2 = np.random.randn(4, 1) * np.sqrt(1 / 4)  # Xavier initialization\n",
        "    b2 = np.zeros((1, 1))  # Xavier initialization\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    no_improvement_epochs = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # 5. Learning Rate Decay\n",
        "        learning_rate = initial_learning_rate / (1 + decay_rate * epoch)\n",
        "\n",
        "        # Forward pass\n",
        "        z1 = np.dot(X, w1) + b1\n",
        "        a1 = relu(z1)  # ReLU activation\n",
        "        z2 = np.dot(a1, w2) + b2\n",
        "        a2 = sigmoid(z2)  # Sigmoid for output\n",
        "\n",
        "        # Compute loss (MSE)\n",
        "        loss = mse_loss(Y, a2)\n",
        "\n",
        "        # Check for early stopping condition\n",
        "        if loss < best_loss:\n",
        "            best_loss = loss\n",
        "            no_improvement_epochs = 0\n",
        "        else:\n",
        "            no_improvement_epochs += 1\n",
        "\n",
        "        if no_improvement_epochs >= patience:\n",
        "            print(f\"Stopping early at epoch {epoch}. Best loss: {best_loss}\")\n",
        "            break\n",
        "\n",
        "        # Backpropagation\n",
        "        error = Y - a2\n",
        "\n",
        "        d_a2 = error * sigmoid_derivative(a2)\n",
        "        d_w2 = np.dot(a1.T, d_a2)\n",
        "        d_b2 = np.sum(d_a2, axis=0)\n",
        "\n",
        "        d_a1 = np.dot(d_a2, w2.T) * relu_derivative(a1)  # ReLU derivative in hidden layer\n",
        "        d_w1 = np.dot(X.T, d_a1)\n",
        "        d_b1 = np.sum(d_a1, axis=0)\n",
        "\n",
        "        # Update weights and biases with learning rate decay\n",
        "        w2 += learning_rate * d_w2\n",
        "        b2 += learning_rate * d_b2\n",
        "        w1 += learning_rate * d_w1\n",
        "        b1 += learning_rate * d_b1\n",
        "\n",
        "    return w1, b1, w2, b2\n",
        "\n",
        "# Predict function\n",
        "def predict(X, w1, b1, w2, b2):\n",
        "    z1 = np.dot(X, w1) + b1\n",
        "    a1 = relu(z1)  # ReLU activation in hidden layer\n",
        "    z2 = np.dot(a1, w2) + b2\n",
        "    a2 = sigmoid(z2)  # Sigmoid activation in output layer\n",
        "    return np.round(a2)\n",
        "\n",
        "# Dataset (XOR logic gate)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Hyperparameters\n",
        "epochs = 10000\n",
        "initial_learning_rate = 0.1  # Starting learning rate\n",
        "decay_rate = 0.001  # Learning rate decay factor\n",
        "patience = 100  # Early stopping patience\n",
        "\n",
        "# Train the model\n",
        "w1, b1, w2, b2 = train(X, Y, epochs, initial_learning_rate, decay_rate, patience)\n",
        "\n",
        "# Test predictions\n",
        "for x, y in zip(X, Y):\n",
        "    print(f\"Input: {x}, Predicted: {predict(x, w1, b1, w2, b2)[0][0]}, Actual: {y[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MboaYocGYAs3",
        "outputId": "4b443771-8333-425a-bbd3-4612ca9726d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [0 0], Predicted: 0.0, Actual: 0\n",
            "Input: [0 1], Predicted: 1.0, Actual: 1\n",
            "Input: [1 0], Predicted: 1.0, Actual: 1\n",
            "Input: [1 1], Predicted: 0.0, Actual: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WzLeo-oTZ8dS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}